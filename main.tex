\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb,mathrsfs,amsmath,hyperref}
\hypersetup{hidelinks,linktoc=none}
\usepackage{graphicx}
\begin{document}
\begin{titlepage}

\centering
\vfill
\includegraphics{iiit}
\vskip1cm

{\bfseries\Large
		International Institute of Information Technology, Hyderabad\\
        \vskip1cm
        Real Analysis MA4.101\\
        \vskip2cm
        Lebesgue Measure\\
        \vskip3cm
       GROUP 19 B2}\\
        \vskip 1cm
{\bfseries        Abhinav Siddharth (2020112007)\\
        \vskip 0.5cm
        Akshit Gureja (2020112004)\\
        \vskip 0.5cm
        Jewel Benny (2020102057)}
    


\end{titlepage}



\newpage
\begin{center}
    {\Large\bfseries\noindent Acknowledgement}
\end{center}

\hfill

"It is not possible to prepare a report without the assistance of other people. This one is certainly no exception."\bigskip

The completion of this report could not have been accomplished without the support of an outstanding group of people, and we would like to thank every one of them.\bigskip

We would like to express our sincere and profound gratitude towards Lakshmi Burra Ma'am, who instilled in us the ability to develop analytical and abstract thinking. She, through her enthusiasm, has always encouraged and supported us. It's her constant and conscientious guidance, which has helped us complete this report.\bigskip

Our heartfelt thanks to our TAs, who have provided their invaluable assistance and advised us on every step of this report. \bigskip

We are also extremely grateful to our parents for their unfathomable moral support along the way and for educating us at the International Institute of Information Technology, Hyderabad, which has provided us the opportunity to write this report.
\bigskip

Lastly, God who has showered his blessing upon us so abundantly. Without his grace, this project would not have become a reality.
\bigskip

We have no words to express our thanks for the valuable support and guidance we have received.

\newpage

\begin{center}
    {\Large\bfseries\noindent Abstract}
\end{center}

This report introduces the concept of Measure Theory, Lebesgue measure, and its applications in the field of probability.\bigskip

We shall build our Lebesgue measure from the ground up intuitively. This paper is not a detailed presentation on the topic, only the most fundamental concepts will be discussed, we will use known concepts where required to retain the readers' interest.\bigskip

The report opens up with the discussion on measure and its properties. They are followed by short sections about some fundamental theorem and outer measures.\bigskip

Next, we establish the concepts of algebras, $\sigma$-algebras, Borel sets along with an in-depth analysis of the Lebesgue measure. The reader will have an excellent understanding using the various examples that have been provided.\bigskip

Later we will come across the application of the Lebesgue measure in probability. A small section on Lebesgue integrals has also been included to pique the reader's interest. We advance through the topic using basic definitions we have learned and some new ones we will learn as we go through the concepts.
\newpage

\begin{center}
    \tableofcontents
\end{center}

\newpage

\section{Introduction}

Measure theory is a branch of mathematics that was developed during the late $19^{th}$ and early $20^{th}$ century by eminent mathematicians like Henri Lebesgue and Emile Borel to name a few. It deals with the study of measures and its applications, one of the most important being probability Theory.

\bigskip

A measure is a mathematical notion to generalise the idea of ‘size’ to almost everything that is measurable, for instance, length, area and volume. There are many measures that are defined, for instance
\begin{itemize}
	\item Lebesgue measure
	\item Jordan measure
	\item Borel measure
	\item Dirac measure
	\item Haar measure
	\item Counting measure
	\item Complex measure
	\item Probability measure
\end{itemize}
In this report, we will be dealing with Lebesgue measures mainly, the notion of which was put forward by Henri Lebesgue. In simple words, a Lebesgue measure is a more generalised notion of length or area or volume to more complicated sets in $\mathbb{R}^n$. The use of Lebesgue measure is found profoundly in probability theory and the Lebesgue integral, both of which are covered in this report.

\bigskip

Probability theory as the name suggests, deals with the study of probability, the measure of likelihood of an event in an experiment. It could be as simple as choosing a card from a deck of cards to more complex fields, like physics (for example, quantum mechanics), biology and finance. Probability theory often uses a notion called a probability measure, which is also covered in this report.

\newpage

\section{Measure}

Measuring a set has been a primary interest of mathematicians for a long time. But how do we measure a set or an object? 

If we have a 3-dimensional object, we could find its volume in 2 different ways, we could fill the container with simple objects or $boxes$ and find their sum, or we could encase the whole container in a box and start chipping away smaller boxes. These approaches work only when our box measure is a properly defined measure.\medskip

The mathematical concept of measure is a generalisation of length in $\mathbb{R}$, area in $\mathbb{R}^2$ or volume in $\mathbb{R}^3$. To avoid splitting into cases depending on the dimension, we shall refer to the $measure$ of E, depending on what Euclidean space $\mathbb{R}^n$ we are using and $E$ is a subset of $\mathbb{R}^n$.\medskip

We know the measure or length of an interval, say $[0,1]$, we also have $(0,1)$ and $(0,1]$, as these are subsets of our initial interval, their measures must not exceed that of $[0,1]$ (monotonic). Let us assume the length of this unit interval be 1. We let the measure be zero, for a single point or an empty set, and infinite if we consider the real line. Ideally, we'd like to associate a non-negative measure $m(E)$ to every subset E of $\mathbb{R}^n$. It should also obey some reasonable properties like $m(A \cup B) = m(A) + m(B)$ whenever A and B are disjoint, we should have $m(A) \leq m(B)$ whenever $A \subset B$, and $m(x+A)=m(A)$ (translation invariant).\medskip

Here, we hit a roadblock in our definition of a measure. From our definition, we can see that two sets having the same number of points need not have the same measure, let $A=[0,1]$ and $B=[0,2]$, there exists a bijection from A to B (x $\mapsto$ 2x), but B is twice as long as A. Also, if we consider the measure of a point to be zero, it is logical that a collection of points must measure zero, and therefore, all sets must have a zero measure.\medskip
 
 Remarkably, it turns out such a measure $does \, not \,exist$. This is quite a surprising fact because it is counter-intuitive. These examples tell us that it is impossible to measure \textbf{every} subset of $\mathbb{R}^n$ applying \textbf{all} the above properties.\medskip
 
 If we are developing a measure $m$ defined on the subsets of $\mathbb{R}$, we hope that these conditions are met:
 \begin{enumerate}
     \item $m(A)$ is defined for every set A of the real numbers;
     \item $0\leq m(A) \leq \infty$;
     \item $m(A) \leq m(B)$ provided $A \subset B$;
     \item $m(\phi) =0 $;
     \item $m(\{a\})=0$ (points are dimensionless);
     \item $m(I)=l(I)$, I is an interval (the measure on an interval should be its length)
     \item $m(A)=m(x+A)$, translation invariance, (location doesn't affect the length, so it shouldn't affect measure)
     \item $m(\bigcup_{1}^{\infty} {A_k}) = \sum_{1}^{\infty}m(A_k)$, for any mutually disjoint sequence $(A_k)$ of subsets of real numbers (countable additivity).
 \end{enumerate}
 Our goal is to construct a measure that satisfies as many conditions as possible, the alternative would be to define a measure only for specific sets.
 
 \subsection{Length of Intervals}
 
 The length of an interval I with end points $a\leq b$, $a,b \in \mathbb{R}$, is defined as:
 $$l(I) = b-a$$
 For example, $l((0,1])=l([0,1])=1$ and $l((1,\infty))=\infty$.
 
 We immediately conclude that, if $I_1$ and $I_2$ are two intervals with $I_1 \subset I_2$, $l(I1) \leq l(I2)$.
 
 \subsection{Cover}
 
 A collection $\{G_{\alpha}\}$ of open sets covers a set A if $A \subset \bigcup G_{\alpha}$. And the collection $\{G_{\alpha}\}$ is called the cover.
 
 \subsubsection{Subcover}
 
 Let C be a cover of a topological space X. A subcover of C is a subset of C that still covers X.
 
 \subsubsection{Compact Set}
 
A set of real numbers is compact if every open cover of the set contains a finite subcover.

\subsection{Heine-Borel Theorem}
A set of real numbers is compact iff it is closed and bounded.

\subsection{Result}
If $I,I_1,I_2,\dots ,I_n$ are bounded open intervals with 

$$ I \subset \bigcup_{1}^{n}I_k ,\; then  \;l(I) \leq \sum l(I_k)$$

The length of an interval can not exceed the length of a $finite$ cover.

\subsection{Proposition}

If $I,I_1,I_2,\dots ,I_n$ are bounded open intervals with $ I \subset \bigcup I_k$, then $l(I) \leq \sum l(I_k)$. Also, $ l(I) \leq inf\{ \sum l(I_k) | I \subset \bigcup I_k, I_k \; bounded \; intervals \}$.\bigskip

Proof: Assume $I =(a,b)$ and let $\epsilon > 0$. The intervals $(a-\epsilon,a+\epsilon),(b+\epsilon,b-\epsilon),I_1,\dots ,I_n$ form an open cover of the compact set $[a,b]$. And by Heine-Borel Theorem, a finite sub collection will cover [a,b] and thus (a,b).
Using 2.5:
$$  l(I) \leq 4\epsilon +  \sum l(I_k)$$

As this holds for any $\epsilon$, $l(I) \leq \sum l(I_k)$, the proof is complete.
\newpage
\section{Lebesgue Outer Measure}

We have seen that every set of real numbers can be covered with a countable collection of open intervals. The outer measure is attempting to approximate the measure from outside using open sets.

\subsection{Definition}

A is any subset of $\mathbb{R}$. Form the collection of all countable covers of A by open intervals. The Lebesgue outer measure of A, $m^*(A)$, is given by
$$m^*(A)= inf\Big\{\sum_{1}^{\infty}l(I_k): A \subset \bigcup_{1}^{\infty} I_k \, , \; I_k \; open \; intervals\Big\}$$

\subsection{Results}
\begin{enumerate}
    \item $m^*$ is a set function, whose domain is all subsets of $\mathbb{R}$, and range is $[0,\infty]$, the non-negative extended real numbers. 
    
    \item The Lebesgue Outer Measure is defined for \textbf{every} subset of $\mathbb{R}$.
    
    \item Outer Measure is monotonic, i.e., if $A \subseteq B$, then $m^*(A) \leq m^*(B)$, any cover of B by open intervals is also a cover of A, and the latter infimum is taken over a larger collection than the former. 

    \item If $(I_k)$ is any countable cover of A by open intervals since infimum is a lower bound,$$ 0 \leq m^*(A) \leq \sum l(I_k)$$
    


\end{enumerate}

\subsection{Jordan Measure}

If we had approximated the length of a set A by using covers by finite sets of intervals, then we would have gotten Jordan outer measure instead of the Lebesgue outer measure. 

We could show that the Jordan outer measure of $ \mathbb{Q} \cap[0,1]$ is 1 even though the Jordan outer measure of any point, or any finite set of points, is 0. Therefore it isn't countably sub-additive, more importantly not defined for many sets, limiting the further usage of the Jordan measure.

\subsection{Outer Measure of any interval is its length}

Proof:  
For a closed interval [a,b], let $\epsilon >0$. Then $(a-\epsilon,b+\epsilon)$ covers $[a,b]$ and length of this interval is $b-a+\epsilon$. Since $\epsilon$ is arbitrary $m^*([a,b]) \leq b-a = l([a,b])$.\medskip

Next let ${I_n}$ be a covering of [a,b] by bounded open intervals. By the Heine-Borel Theorem, there exists a finite subset A of $I_n$'s covering [a,b]. So $a \in I_1$ for some $I_1 =(a_1,b_1) \in A$. Also, if $b_1 \leq b$, then $b_1 \in I_2 $ for some $I_2 =(a_2,b_2) \in A$. Similarly we can construct $I_1,I_2,\dots,I_k$. Then
$$ \sum l(I_n) \geq \sum_{i=1}^k l(I_i) = \sum_{i=1}^{k}(b_i - a_i)$$
$$=(b_k-a_k) +(b_{k-1} -a_{k-1})+ \dots + (b_1 - a_1) $$
$$ >b_k -a_1$$
Since $a_1<a$ and $b_k>b$, then $ \sum l(I_n) > b_k -a_1 $. So, $m^*([a,b]) = b-a = l([a,b])$.\medskip

If I is an unbounded interval, then given any natural number $n \in N$, there is a closed interval $J \subset I$ with $l(J)=n$. Hence $m^*(I) \geq m^*(J) = l(J)=n$. Since $m^*(I) \geq n \, and \, n \in N$ is arbitrary, then $m^*(I)=\infty=l(I)$. 

\subsection{Outer Measure is translation invariant}
$$m^*(A)=m^*(A+y)$$

Proof: Suppose $m^*(A) = M < \infty$. Then for all $\epsilon > 0 $ there exist ${I_n}$ bounded open intervals, such that they cover A. And from Sec 2.5 $\sum l(I_n) < M+ \epsilon$, so if $y \in \mathbb{R}$, then ${I_{n}+y}$ is a covering of A+y and so $m^{*}(A+y) \leq \sum l(I_n + y ) = \sum l(I_n) < M + \epsilon$ .Therefore $m^*(A+y) \leq M$.\medskip

Now, let ${J_n}$ be a collection of bounded open intervals such that $\cup J_n \supset A+y $.Assume that $\sum l(J_n)< M$. Then ${J_n-y}$ is a covering of A and $\sum l(J_n-y)=\sum l(J_n) < M$, a contradiction. So, $\sum l(J_n) \geq M$ and hence $m^*(A)\geq M$. So $m^*(A)=m^*(A+y)=M$.\medskip

Suppose $m^*(A)= \infty$.Then for any$\{I_n\}_{n=1}^{\infty} $ a set of bounded open intervals such that $A \subset \cup I_n$, we must
have$\sum l(I_n) =\infty$. Consider A+y. For any $\{J_n\}_{n=1}^{\infty} $ a set of bounded open intervals such that $A+y \subset \cup J_n$, the collection $\{J_n - y\}_{n=1}^{\infty} $ is a set of bounded open intervals such that $A+y \subset \cup J_n -y$. \smallskip

So $\sum l(J_n - y) =\infty$. But l($J_n$) =l($J_n - y$), so we must have $\sum l(J_n) =\infty$. Since $\{J_n\}_{n=1}^{\infty} $ is an arbitrary collection of bounded open intervals covering A+y, we must have $m^*(A)=m^*(A+y)= \infty$. 

\subsection{Outer Measure is countably sub-additive}

That is, if $\{E_k\}_{k=1}^{\infty} $ is any countable collection of sets, then
$$ m^*(\bigcup_{k=1}^{\infty} E_k) \leq \sum_{k=1}^{\infty} m^{*}(E_k)$$

Proof: If one of the $E_k$'s has an infinite outer measure, the inequality holds trivially. We, therefore, suppose each of the $E_k$'s has a finite outer measure. Let $\epsilon > 0$. For each natural number k, there is a countable collection $\{ I_{k,i} \}_{i=1}^{\infty}$ of open bounded intervals for which
$$ E_k \subseteq \bigcup_{i=1}^{\infty} \{ I_{k,i} \} \; and \; \sum_{i=1}^{\infty} l(I_{k,i}) < m^{*}(E_k) +\frac{\epsilon}{2^k}  $$

Now, $\{I_{k,i}\}_{1 \leq k , i \leq \infty}$ is a countable collection of open, bounded intervals that covers $\cup_{k=1}^{\infty} E_k$: the collection is countable since it is a countable collection of countable collections. Thus,

$$ m^{*}(\bigcup_{k=1}^{\infty} E_k) \leq \sum_{1\leq k,i<\infty } l(I_{k,i})= \sum_{k=1}^{\infty}[\sum_{i=1}^{\infty} l(I_{k,i})]$$
$$\;\;\;<\sum_{k=1}^{\infty}[m^{*}(E_k) + \frac{\epsilon}{2^k}]$$
$$  m^{*}(\bigcup_{k=1}^{\infty} E_k) \leq [\sum_{k=1}^{\infty}m^{*}(E_k)]+\epsilon$$

Since this holds for each $\epsilon>0$, it also holds for $\epsilon=0$. The proof is complete.

The finite sub-additivity property follows from countable sub-additivity by taking $E_k = \phi$ for $k>n$.

\subsection{Countable Sets have outer measure zero}
Let C be a  countable set enumerated as $C=\{c_k\}_{k=1}^\infty$. Let $\epsilon>0.$ For each natural number k, define $I_k=(c_k-{\frac{\epsilon}{2^{k+1}}},c_k+{\frac{\epsilon}{2^{k+1}}}).$ The countable collection of open intervals $\{I_k\}_{k=1}^\infty$ covers C. Therefore

$$ 0 \leq m^*(C) \leq \sum_{k=1}^{\infty}l(I_k) = \sum_{k=1}^{\infty} \frac{\epsilon}{2^k}= \epsilon$$

This inequality holds for all $\epsilon>0$. Hence $m^*(C)=0$.

\subsubsection{$[0,1]$ is not countable}

As seen in Sec.3.3,  $[0,1]$ has an outer measure of 1, whereas all countable sets have a measure 0. Therefore $[0,1]$ is not countable.
\newpage
\section{$\sigma$-Algebra of Lebesgue Measurable sets}

Unfortunately, the outer measure fails to be countably additive on all subsets of $\mathbb{R}$, and it is not even finitely additive. A famous example is the Vitali Set, found by Giuseppe Vitali in 1905 (Refer to Sec. result 2 of 3.2 \& 5.3).\smallskip

However, we can salvage matters by measuring a particular class of sets in $\mathbb{R}$, hereafter called the measurable sets. Once we restrict ourselves to measurable sets, we recover all the properties again.

We shall be doing this using Caratheodory's Criterion rather than defining the Lebesgue inner measure (both the definitions are equivalent).

\subsection{Caratheodory's Measurability Criteria}

E is any set of real numbers. If

$$m^*(X)= m^*(X \cap E) + m^*(x \cap E^c) $$
for every set X of real numbers, then the set E is said to be Lebesgue Measurable set of real numbers.

\subsection{Results}
\begin{enumerate}
    \item Any set of outer measure 0 is measurable. In other words, any countable set is measurable.
    \item The union of a finite collection of measurable sets is measurable. This can be inferred using set identities and finite sub-additivity property of outer measure, then applying induction.
    \item The union of a countable collection of measurable sets is measurable.
\end{enumerate}

\subsection{$\sigma$-Algebra}
A $\sigma$-algebra (or $\sigma$-field) $\Sigma$ on a set $\Omega$ is a subset of $P(\Omega)$ (the power set of $\Omega$) such that it satisfies the following properties -


\begin{enumerate}
	\item $\Omega$ $\in$ $\Sigma$ \textit{(property 1)}
	\item If A is an element of $\Sigma$ then its complement also is an element of $\Sigma$ i.e A $\in$ $\Sigma$ $\Rightarrow$ A$^c$ $\in$ $\Sigma$ \textit{(\textit{property 2})}
	\item If $A_i \in \Sigma$, 
	$i\in \mathbb{N}$, then $\bigcup\limits_{i=1}^{n}A_i \in \Sigma$\textit{(\textit{property 3})}
\end{enumerate}



\subsubsection{Examples}
\begin{enumerate}
	\item Consider $\Sigma$ $=$ \{$\phi$, $\Omega$\}. The given set is a $\sigma$-algebra on $\Omega$ as it satisfies all the properties needed. Observe that $\phi$ is also included in $\Sigma$ by \textit{property 2}. \textit{Property 1} is also satisfied by the given $\sigma$-algebra. $\phi $ $\cup$ $\Omega$ = $\Omega$ $\in \Sigma$, so \textit{property 3} is also satisfied.
	\item Consider $\Sigma$ = $P(\Omega)$. Then, $\Sigma$ satisfies \textit{property 1} as $\Omega$ $\in$ $\Sigma$. Furthermore, $X^c$ = $\phi$ $\in$ $\Sigma$ and hence it satisfies \textit{property 2}. As $\Sigma$ contains all the subsets of $\Omega$, it is guaranteed that the union of any number of subsets of $\Omega$ exists in $\Sigma$, and hence satisfying \textit{property 3}. Hence $\Sigma$ = $P(\Omega)$ is a $\sigma$-algebra. 
	\item Consider $\Sigma$ = \{$\phi$, \{1\}, \{2\}, \{1, 2\}, $\Omega$\} and $\Omega$ = \{1, 2, 3\}. Here, $\Sigma$ is \textbf{not} a $\sigma$-algebra on $\Omega$ as \{1, 2\}$^c$ = \{3\} is not an element of $\Sigma$, and hence $\Sigma$ does not satisfy \textit{property 2}.
\end{enumerate}


\subsubsection{Proposition 1}
If $\Sigma$ is a $\sigma$-algebra on $\Omega$, and A$_1$, A$_2$, A$_3$,....A$_n$ $\in$ $\Sigma$, then $\bigcap\limits_{i=1}^n$A$_i$ $\in$ $\Sigma$.

\textbf{Proof: }If A$_1$, A$_2$, A$_3$,....A$_n$ $\in$ $\Sigma$, then A$_1^c$, A$_2^c$, A$_3^c$,....A$_n^c$ $\in$ $\Sigma$ and $\bigcup\limits_{i=1}^n$A$_i^c$ $\in$ $\Sigma$. Then by \textit{property 2}, $(\bigcup\limits_{i=1}^n$A$_i^c)^c$ = $\bigcap\limits_{i=1}^n$A$_i$ $\in$ $\Sigma$.


\subsubsection{Proposition 2}
If $\Sigma$ is a $\sigma$-algebra on $\Omega$ and A, B $\in$ $\Sigma$, then A$\setminus$B = A - B $\in$ $\Sigma$.\medskip

\textbf{Proof: }If B $\in$ $\Sigma$, then B$^c$ $\in$ $\Sigma$ by  \textit{property 2}. So, A $\cap$ B$^c$ = A$\setminus$B $\in$ $\Sigma$ (As seen in proposition 1).


\subsubsection{Proposition 3}
If $\Sigma_i$ is a $\sigma$-algebra on $\Omega$, i $\in \mathbb{N}$, then $\bigcap\limits_{i=1}^n$ $\Sigma_i$ is also a $\sigma$-algebra on $\Omega$.\medskip

\textbf{Proof: }Consider the $\sigma$-algebras $\Sigma_1$, $\Sigma_2$, $\Sigma_3$,... $\Sigma_n$ defined on $\Omega$, then the smallest intersection of all such $\sigma$-algebras would be \{$\phi$, $\Omega$\}, which is a $\sigma$-algebra by definition. Also, if A is an element of the intersection, then A$^c$ would also be an element of the intersection, which satisfies \textit{property 2}. Also, A $\cup$ A$^c$ = $\Omega$ $\in$ $\Sigma$ which satisfies properties 1 and 3.



\subsubsection{Proposition 4}
For $Y$ $\subseteq$ P($\Omega$), there exists a smallest $\sigma$-algebra that contains $Y$, called the $\sigma$-algebra generated by $Y$, given by the intersection of all such $\sigma$-algebras $\Sigma$ such that $\Sigma \supseteq Y$. That is, $\sigma$($Y$) = $\bigcap\limits_{\Sigma \supseteq Y}\Sigma$.\bigskip

\textbf{Proof: }Consider $\sigma$-algebras $\Sigma_1$, $\Sigma_2$, $\Sigma_3$,....  $\Sigma_n$ $\supseteq $ $Y$ defined on $\Omega$. Then $\bigcap\limits_{i=1}^n \Sigma_i \supseteq Y$. As $Y \in$ $\Sigma_i$, $Y^c \in \Sigma_i$ for i = 1, 2, 3...n which satisfies \textit{property 2}. Furthermore, $\Omega$ $\in \Sigma_i$ which satisfies \textit{property 1}. $Y \cup Y^c$ = $\Omega$ which satisfies \textit{property 3}. Hence $\sigma(Y)$ is a $\sigma$-algebra.

For example, consider $\Omega$ = \{1, 2, 3, 4\} and $Y$ = \{\{1\}, \{2\}\}. Then the smallest $\sigma$-algebra on $\Omega$ containing $Y$ is $\sigma(Y)$ = \{$\phi$, \{1\}, \{2\}, \{1, 2\}, \{3, 4\}, \{1, 3, 4\}, \{2, 3, 4\}, $\Omega$\}. Also note that if $Y$ is a $\sigma$-algebra, then $\sigma(Y)$ = $Y$.

\subsection{Every interval is measurable}
From the preceding propositions, we immediately conclude that the collection of measurable sets is a $\sigma$-algebra. Also, Lebesgue outer measure $m^*$, written as $m$ when restricted to the $\sigma$-algebra $E$ subsets of $R$ satisfying Carathedory's condition, is countably additive on $E$. In other words, $m$ is countably additive on Lebesgue measurable subsets of R.
\medskip

It can further be shown Intervals satisfy Caratheodory's condition, using the Heine-Borel theorem. But we can use Borel sets to extend our applicability of Lebesgue measure to a much larger group of subsets.

\subsection{Borel Sets}
The $\sigma$-algebra generated by the collection of all open intervals of R is called the Borel $\sigma$-algebra $\mathscr{B}$.

Therefore, since the measurable sets are a $\sigma$-algebra containing all open sets, every Borel set of real numbers is Lebesgue measurable. $\mathscr{B}$ contains about every set that usually comes up in analysis.

\subsubsection{Contents of Borel Sets}
\begin{itemize}
    \item Open intervals
    \item Open sets
    \item Closed intervals
    \item Closed sets
    \item Compact sets
    \item Left open, right closed sets
    \item Right open, left closed sets
    \item All intervals
\end{itemize}

Every Borel set is Lebesgue measurable, but not vice-versa. There exist sets that are Lebesgue measurable, which are not Borel sets.
%add examples here
The collection of all Lebesgue measurable sets is a $\sigma$-algebra $\mathscr{M}$, and $\mathscr{B}$, the collection of Borel sets, then
$$\mathscr{B} \subset \mathscr{M} \subset 2^{\mathbb{R}} $$
\newpage
\section{Lebesgue Measure}

By restricting outer measure to a class of measurable sets, we can define the Lebesgue measure. It is denoted by $m$. If E is a measurable set, its Lebesgue measure is defined to be
$$m(E)=m^*(E)$$

We can use all our previous results to determine the Lebesgue measure of specific sets of real numbers. Note that all following sets are presumed to be Lebesgue measurable sets of real numbers.

We can infer the following properties for Lebesgue measurable sets-

\subsection{Properties}
\begin{enumerate}
    \item $m(\phi)$=$m(\{a\})$ = 0, $m(\mathbb{R})$ = $\infty$.
    \item $m(I)$ = $l(I)$.
    \item $m$(countable set) = 0, $m$(subset of a set with measure 0) = 0.
    \item If $E$ is measurable, then $E^c$ is also measurable.
    \item $m$ is translation invariant i.e $m(x + E)$ = $m(E)$ for all $x$ $\in$ $\mathbb{R}$
    \item $m(\bigcup \limits_{i=1}^\infty A_i)$ = $\sum \limits_{i=1}^\infty m(A_i)$ for $A_i \cap A_j = \phi$ for $i \neq j$ for all $A_i$ $\in$ $\Sigma$, a $\sigma$-algebra ($\sigma$-additivity).
    \item $m(E_1 \cup E_2) + m(E_1 \cap E_2) = m(E_1)+ m(E_2)$.
    \item If $E_1$, $E_2$, $E_3$,.... $E_n$ are measurable, then $\bigcup\limits_{i=1}^{n}E_i$ and $\bigcap\limits_{i=1}^{n}E_i$ are measurable.
    \item $m(E_1) \leq m(E_2)\, if \, E_1 \subset E_2$. If in addition, $m(E_2) <\infty$, then $m(E_2)-m(E_1)=m(E_2-E_1)$.
    \item If $E_1 \subset E_2 \subset E_3 \dots$ then $m(\cup E_k)=m(\lim E_k)=\lim m(E_k)$
    \item If $E_1 \supset E_2 \supset E_3 \dots$ and $m(E_1) < \infty $, then $m(\cap     E_k)=m(\lim E_k)=\lim m(E_k)$
    \item If $m(\cup E_k) < \infty$, then $\lim sup\, m(E_k) \leq m(\lim sup E_k)$
    \item  $ m(\lim inf E_k) \leq \lim inf\, m(E_k) $
    \item If $\lim inf E_k = \lim sup E_k$ and $m(\cup E_k)<\infty$, then $m(\lim E_k)=\lim m(E_k)$
\end{enumerate}


\subsection{Not all sets are Lebesgue measurable}


\textbf{Proof: }We define an equivalence relation $x \sim y$ as $x - y$ $\in$ $\mathbb{Q}$ for $x, y$  $\in$ $\mathbb{R}$. This establishes equivalence classes $[x]$ = \{$x + r$ : $r$ $\in$ $\mathbb{Q}$\}. We define $A \subset [0, 1]$ with the following properties-

\begin{itemize}
	\item For each $[x]$, there is a $p \in A$ with $p \in [x]$.
	\item For all $p, q \in A$, if $p, q \in [x]$, then $p = q$.
\end{itemize}

The Axiom of Choice allows us to make such a set. Let $A_n = A + r_n$, where $r_n (n \in \mathbb{N})$ is an enumeration of $\mathbb{Q} \cap [-1,1]$. Then we can claim that $n \neq m \Rightarrow A_n \cap A_m = \phi$. We prove this by contradiction. Assume that there exists $x$ $\in$ $A_n \cap A_m$ for $n \neq m$.

Let $x = r_n + a_n,$ $a_n \in A$ and $x= r_m + a_m,$ $a_m \in A$. Then,
$$a_n + r_n = a_m + r_m$$
$$\Rightarrow a_n - a_m = r_m - r_n \in \mathbb{Q}$$
Then, $a_n$ and $a_m$ satisfies the equivalence relation $a_n \sim a_m$. So,
$$a_n, a_m \in [a_m]$$
$$\Rightarrow a_n = a_m$$
$$\Rightarrow r_n = r_m$$
$$\Rightarrow n = m$$
Which is a contradiction to our assumption. So, we can claim that 
$$[0, 1] \subset \bigcup\limits_{n=1}^\infty A_n \subset [-1, 2]$$
Assume that $m$ is a measure on $P(\mathbb{R})$. Then,
$$m([0, 1]) \leq m(\bigcup\limits_{n=1}^\infty A_n) \leq m([-1, 2])$$
$$\Rightarrow 1 \leq m(\bigcup\limits_{n=1}^\infty A_n) \leq 3 $$
By $\sigma$-additivity of Lebesgue measures,
$$1 \leq \sum\limits_{n=1}^\infty m(A_n) \leq 3$$
By translational invariance of Lebesgue measures,
$$1 \leq \sum\limits_{n=1}^\infty m(A) \leq 3 $$
$$\Rightarrow 1 \leq \lim_{n \rightarrow \infty} n m(A) \leq 3 $$
Which is not possible, as $\lim_{n \rightarrow \infty} n m(A)$ can take only one of two values - either 0 or $\infty$. Hence, the set $A$ is not Lebesgue measurable.

\subsection{Examples}
\begin{itemize}
	\item Consider an interval $[2, 5]$ on $\mathbb{R}$. Then, the Lebesgue measure of the interval $m([2, 5]$ is given by $l([2, 5]) = 5 - 2 = 3$. Note that the Lebesgue measures of $(2, 5)$, $(2, 5]$ and $[2, 5)$ are also 3.
	\item The set of all rational numbers given by $\mathbb{Q}$ has Lebesgue measure equal to zero.
	\item The set $\{1, 2, 3, 4\}$ has Lebesgue measure equal to zero.
	\item Vitali sets are \textbf{not} Lebesgue measurable (see the proof of existence of non-measurable sets given previously in Sec.5.2).
\end{itemize}

\subsection{Cantor Set}
The Cantor ternary set is an example of an uncountable set that has Lebesgue measure equal to 0. The cantor ternary set $\mathcal{C}$ is given by
	$$\mathcal{C} = \bigcap\limits_{n=1}^\infty C_n$$
	where
	$$C_n = \frac{C_{n-1}}{3} \cup ( \frac{2}{3} + \frac{C_{n-1}}{3} ) \  \forall\ n \geq 1 \ and\ C_0 =  [0, 1]$$
	Note that while building the Cantor set, we remove $\frac{1}{3}$ of each interval, meaning at step $n-1$ we remove $(\frac{1}{3})^n$, $2^{n-1}$ times, so we remove a total of
	$$ \sum_{n=1}^{\infty} \frac{2^{n-1}}{3^n}=\frac{1}{3}\sum_{n=1}^{\infty} (\frac{2}{3})^n=\frac{1}{3}\times \frac{1}{1-\frac{2}{3}}=1$$
	As the length of the interval removed is equal to the initial measure of [0,1], Lebesgue measure of the Cantor Set is equal to 0.
\subsection{Outer and Inner approximation of Lebesgue measure}

Measurable sets possess the following excision property: If A is a measurable set of finite outer measure that is contained in B, then
$$ m^*(B \sim A)= m^*(B)-m^*(A).$$
This follows from Sec 4.1
$$m^*(B)=m^*(B \cap A) + m^*(B \cap A^C)= m^*(A)+  m^*(B \sim A).$$

{\large \textbf{Theorem}}

For an arbitrary subset E of $\mathbb{R}$, the following assertions are equivalent to the measurability of E

\begin{enumerate}

    \item For each $\epsilon >0$, there is an open set $O$ containing E for which $m^{*}(O \sim E)<\epsilon$.(Outer approximation by open sets)
    \item There is a $G_{\delta}$ set $G$ containing $E$ for which $m*(G \sim E) =0$. 
    
    \item For each $\epsilon >0$, there is an closed set $F$ contained in $E$ for which $m^{*}(E \sim F)<\epsilon$.(Inner approximation by closed sets)
    \item There is a $F_{\sigma}$ set $F$ contained in $E$ for which $m*(E \sim F) =0$. 
\end{enumerate}

Here, $G_{\delta}$ denotes a subset that is a countable intersection of open sets, and $F_{\sigma}$ is a countable union of closed sets.

\subsection{Extension to $\mathbb{R}^n$}

The modern construction of the Lebesgue Measure is an application of 
Caratheodory's extension theorem, which was used to prove Caratheodory's criterion.

Fix $n \in \mathbb{N}$. A $box$ is a set of the form:
$$ B= \prod_{i=1}^{n}[a_i,b_i]$$
where $b_i \geq a_i$, and the product symbol represents a Cartesian product. The volume of this box is defined to be
$$ vol(B)=\prod_{i=1}^{n}l([a_i,b_i]).$$
For any subset A of $\mathbb{R}^n$, we can define its outer measure $\lambda^{*}(A)$ by:
$$\lambda^{*}(A)=inf\Big\{ \sum_{B \in C}vol(B): C\; is\; a\; countable \;collection\; of \;boxes\; whose\; union\; covers \; A\Big\}$$
We then define the set A to be Lebesgue-measurable if for every subset S of $\mathbb{R}^n$, 
$$\lambda^{*}(S)= \lambda^{*}(S \cap A) + \lambda^{*}(S \cap A^C)$$
These Lebesgue measurable sets form a $\sigma$-algebra, and the Lebesgue measure is defined by $\lambda(A)=\lambda^{*}(A)$ for any Lebesgue measurable set A.
\begin{itemize}
    \item The Lebesgue measure of the Cartesian product of intervals $[2, 5]$ and $[2, 4]$ is $(5-2)(4-2) = 6$, which is equal to the area of the corresponding rectangle.
\end{itemize}

\subsection{Banach-Tarski Paradox}
Banach-Tarski paradox is a famous example to be demonstrated here. The Banach-Tarski theorem tells us that given a sphere in 3-dimensional space, there exists a decomposition of the ball into a number of finite number of disjoint subsets, which can be put back in a different way to yield two identical copies of the original sphere. This can be done using as few as 5 pieces.\medskip

The reason this theorem is called a paradox is that it contradicts our intuition about volume.

While the reassembly process involves only moving the pieces around and rotating them without changing their shape, which is closed under the Lebesgue measure, some of the five or more sets in which you divide the sphere are not Lebesgue measurable.

Unlike most theorems in geometry, the proof for the Banach-Tarski theorem itself requires using the axiom of choice, which allows the construction of non-measurable sets.\medskip

As some of the sets are non-measurable, it's not possible to define a volume to such sets as seen before. It is, therefore, absurd to add these 'volumes' in order to double their initial volume. However, note that the initial sphere and the final spheres obtained are measurable.
\newpage
\section{Probability and Measures}


We'll start from the very basics of probability theory and work our way up to learn more complex concepts and the involvement of Measure theory in probability.

\subsection{Random Experiment}

An experiment whose outcome cannot be predicted with certainty even if the experiment is conducted several times under identical conditions.

\subsection{Sample Space ($\Omega$)}
    
The sample space is defined as the set of all possible outcomes of an experiment.

For example:
\begin{enumerate}
    \item Throwing a dice : $\Omega$ = $\{1,2,3,4,5,6\}.$
    \item  Tossing a coin twice : $\Omega$ = $\{HH, TT, HT, TH\}$, where 'H' represents that the heads and 'T' represents the tails.
\end{enumerate}


In probability theory, an outcome is denoted by $\omega$, and from the definition of the sample space, we can say that $\omega$ $\in$ $\Omega$.
So an outcome is nothing but an element of the sample space.

Observe that in probability, the outcome is the source of randomness and is not in our control in a random experiment.
\bigskip

NOTE - The sample space of an experiment can be countable or uncountable. The sample space of an experiment like tossing a coin n times is countable with 2$^{n}$ outcomes, whereas if we want to determine the speed with which the coin tossed would land back is a set of positive real numbers, and the sample space would be uncountable. Another example of uncountable sample space could be the set of all points on the circumference of a circle.\bigskip

One more thing to discuss before going ahead is that we are often not interested in a particular outcome but a subset of the sample space while discussing probability theory. For example - when a dice is rolled, we might be interested if the outcome is an even number $\{2,4,6\}$ or a prime number $\{2,3,5\}$ rather than the outcome being a particular number like 2 or 5.

\subsection{Events and event space}
The subset of the sample space $\Omega$, which is of our interest, is referred to as an event. The subset is referred to as an event space.
We understand by taking an example of a coin tossed thrice and our outcome being at least 2 tails, so our event space is $\{TTH, HTT, THT, TTT\}$ which, as we stated, is a subset of a sample space. 

We say that an event $E$ $\subseteq$ $\Omega$ has occurred or taken place iff $\omega$ $\in$ $E$.

\subsection{Algebra and probability theory}

Now, before writing down everything mathematically, let's discuss how we will link the two concepts.

If we say that an event $E$ is in our interest, we can always say that the non-occurrence of $E$ would also interest us. Thus $E^{c}$, that is the complement of $E$, also would interest us.

If two events $M$ and $N$ are of our interest, then the event $M\cup N$ is also of our interest as  $M\cup N$ will have our favourable outcome.

Also, when any outcome is obtained, $\Omega$ has always occurred and always interests us.

As we have stated earlier, an algebra is a collection of subsets of $\Omega$ with certain properties, as we have already discussed.

Now we are sufficiently equipped to expand our ideas of algebra to probability.

We denote the sample space by $\Omega$, the $\sigma$-algebra(the collection of subsets) on $\Omega$ by $\Sigma$.

\subsection{Measurable space}
($\Omega$, $\Sigma$) is referred to as a measurable space.
Probability is a special case of Measure theory, and we'll see how.
\bigskip

Measure is a function $\mu$ : $\Sigma$ $\rightarrow$ [0, $\infty$], such that
\begin{enumerate}
    \item $\mu(\phi)$ = 0
    \item If $A_{1}, A_{2} ,A_{3} ....$ are a countable collection of disjoint measurable sets, then  $$\mu(\bigcup_{i=1}^{\infty} {A_i}) = \sum_{i=1}^{\infty}\mu(A_i).$$ This is referred to as the countable additivity axiom.
\end{enumerate}
So a measure is nothing but a mapping of the subsets included in $\Sigma$ to [0, $\infty$].
\bigskip

We say that
\begin{enumerate}
    \item If $\mu(\Omega)$ $<$ $\infty$ , $\mu$ is called a finite measure.
    \item If $\mu(\Omega)$ = $\infty$ , $\mu$ is called a infinite measure.
    \item If $\mu(\Omega)$ =  1 , $\mu$ is called a probability measure.
\end{enumerate}

So a probability measure is a special case of finite measure with the measure of $\Omega$ being 1.
\bigskip

\subsection{Probability Measure}

A probability measure on S can be expressed on $X$ as
$$P(A) = \frac{\mu(A)}{\mu(X)}, \ A \in X$$
Where $0 < \mu(X) < \infty$ is a measure.\medskip

Consider that $m$ is a Lebesgue measure on $\mathbb{R}^n$. If $X \subseteq  \mathbb{R}^n$ and $0 < m(X) < \infty$, then
$$P(A) = \frac{m(A)}{m(X)}\,, \ A \subseteq X$$
Then we can define a probability measure($P$) on ($\Omega$, $\Sigma$) as a function $P$: $\Sigma$ $\rightarrow$ [0,1] such that -
\begin{enumerate}
    \item $P(\phi)$ = 0
    \item $P(\Sigma)$ = 1
    \item If $A_{1}, A_{2} .... $ are disjoint $\Sigma$ measurable sets, then
    $$P(\bigcup_{i=1}^{\infty} {A_i}) = \sum_{i=1}^{\infty}P(A_i)$$
\end{enumerate}

\subsection{Probability Space}

The triple ($\Omega,$ $\Sigma,$ $P$) is referred to as a probability space where

$\Omega$ : Sample space

$\Sigma$ : Event Space

$P$ : Probability Measure

So, in probability, $\Sigma$ -measurable sets are called events.

\subsection{Properties of probability measure}
\begin{enumerate}
    \item $0 \le P(A) \le 1$
    \item $P(A^{c})$ = 1 - $P(A)$, $\forall\  A \in \Sigma$
    \newline \textbf{Proof: } $A$ and $A^c$ are disjoint. So,
    $$ P(A \cup A^c) = P(A) + P(A^c)$$
    $A \cup A^c$ gives the entire sample space. So, $P(A \cup A^c) = 1$
    $$\Rightarrow 1 = P(A) + P(A^c)$$
    $$\Rightarrow P(A^c) = 1 - P(A)$$
    \item if $A=B$, then $P(A) = P(B)$
    \item Monotonicity: if $A \subset B \Rightarrow P(A) \le P(B)$
    \item $P(B\cap A^{c}) = P(B) - P(A\cap B)$
    \item $P(A\cup B) = P(A) + P(B) - P(A\cap B)$\medskip
    
    In general, by the inclusion-exclusion principle,
    $$P(\bigcup \limits_{i=1}^nA_i) = \sum \limits_iP(A_i) - \sum \limits_{i<j}P(A_i \cap A_j)$$ 
    $$ + \sum \limits_{i<j<k}P(A_i \cap A_j \cap A_k) + ....(-1)^{n+1}P(A_1 \cap A_2 \cap A_3....\cap A_n)$$
    \item Finite additivity:\hfill If $A_{1}, A_{2} ... A_{n} \ \in \ \Sigma$ and suppose they are disjoint. Then,
    $$P(\bigcup_{1}^{n} {A_k}) = \sum_{1}^{n}P(A_k)$$
\end{enumerate}
\subsection{Propositions}
\begin{enumerate}
	\item If $E_1 \subset E_2 \subset E_3 \ ....\subset$ and $E = \bigcup \limits_{i=1}^\infty E_i$ lies in $\Sigma$, then 
	$$lim_{n \rightarrow \infty}P(E_n) = P(E)$$
	\textbf{Proof: }It is obvious that this limit does exist and is $\leq 1$. Let $F_i = E_i - E_{i-1}$ for $i \geq 2$ and $F_1 = E_1$. Then, $F_j \cap F_k = \phi$ for all $j \neq k$. So, we can write,
	$$A_n = \bigcup \limits_{i=1}^\infty B_i \ \textrm{and}\  A = \bigcup \limits_{i=1}^\infty B_i$$
	By countable additivity,
	$$P(A) = \sum \limits_{i=1}^\infty P(B_i) = \lim_{n \rightarrow \infty } \sum \limits_{i=1}^n P(B_i) = \lim_{n \rightarrow \infty}P(A_n) $$
	\item If $E_1 \supset E_2 \supset E_3 \ ....\supset$ and $E = \bigcap \limits_{i=1}^\infty E_i$ lies in $\Sigma$, then 
	$$lim_{n \rightarrow \infty}P(E_n) = P(E)$$
	\textbf{Proof: } Given $E_1 \supset E_2 \supset E_3 \ ....\supset$. So, $$E_1^c \subset E_2^c \subset E_3^c \ ....\subset \ \textrm{and}\  E^c =  (\bigcap \limits_{i=1}^\infty E_i)^c = \bigcup \limits_{i=1}^\infty E_i^c$$
	So, from proposition 1,
	$$P(E^c) = \lim_{n \rightarrow \infty}P(E_n^c)$$
	$$P(E) = 1 - P(E^c) = 1 - \lim_{n \rightarrow \infty}P(E_n^c) = \lim_{n \rightarrow \infty}(1- P(E_n^c)) = \lim_{n \rightarrow \infty}P(E_n)$$
	\item If $E_1, E_2, E_3,....$ are events and $E = \bigcup \limits_{i=1}^\infty E_i$, then 
	$$P(E) \leq \sum \limits_{i=1}^\infty P(E_i)$$
	\textbf{Proof: }Let $F_1 = E_1$ and $F_n = E_n - (\bigcup \limits_{i=1}^{n-1}E_i)$. Then, $F_j \cap F_k = \phi $ for all $j \neq k$. Then
	$$E = \bigcup \limits_{i=1}^\infty F_i$$
	And by countable additivity
	$$P(E) = \sum \limits_{i=1}^\infty P(F_i)$$
	Since $F_i \subseteq E_i$, $P(F_i) \leq P(E_i)$
	$$\sum \limits_{i=1}^\infty P(F_i) \leq \sum \limits_{i=1}^\infty P(E_i)$$
	Then
	$$P(E) \leq \sum \limits_{i=1}^\infty P(E_i)$$
\end{enumerate}	

From our analysis so far, it is evident from the one to one correspondence of probability theory and measure theory that probability measures are like Lebesgue measures when the range is restricted to the interval [0,1].	

\subsection{Dyadic intervals}

Let $i$ be a positive integer, Let $(\frac{j-1}{2^{i}}, \frac{j}{2^{i}}]$, be intervals of a $\Sigma$ for $1 \le j \le 2^{i}$, $i$ $\in$ $\mathbb{N}$. These half-open intervals are referred to as Dyadic intervals in (0,1] = $\Omega$. Here ($\Omega, \Sigma, P)$ is the probability space.
 
\bigskip

Considering our event to be a die throw we think of the interval $(0,\frac{1}{6}]$ to represent the outcome that the die shows 1, $(\frac{1}{6},\frac{1}{3}]$ to represent the outcome 2, $(\frac{1}{3}, \frac{1}{2}]$ to represent the outcome 3 and so on. Note that the measure of each interval is $\frac{1}{6}$. This tells us that probability of each outcome is $\frac{1}{6}$.
\bigskip

If our event had been getting a prime number (2 or 3 or 5), our event space would correspond to the union of the intervals. So, the interval $(\frac{1}{3}, \frac{1}{2}] \cup (\frac{1}{2}, \frac{2}{3}] \cup (\frac{2}{3},\frac{5}{6}]$ and the Lebesgue measure on this interval by the additivity property on Lebesgue measure to be $\frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{1}{2}$ which is indeed the probability for our desired event.


\newpage
\section{Lebesgue Integration}

The Lebesgue integral is a powerful tool and a further extension of the Lebesgue measure, which can be used to integrate more functions compared to the Riemann integral or even the Riemann–Stieltjes integral. 
This integral plays an important role in probability theory.

The Lebesgue integral approximates the area under a curve using horizontal strips or using the measure of an interval, whereas the Riemann integral uses vertical strips.

This topic will not be covered in full, as it requires a more profound discussion into Measurable functions and sequences of functions, but we can see some applications of the integral.

\subsection{Explanation}

\begin{center}
    "I have to pay a certain sum, which I have collected in my pocket. I take the bills and coins out of my pocket and give them to the creditor in the order I find them until I have reached the total sum. This is the Riemann integral. But I can proceed differently. After I have taken all the money out of my pocket I order the bills and coins according to identical values and then I pay the several heaps one after the other to the creditor. This is my integral."
\end{center}

This explanation was given by Henri Lebesgue himself, and it is futile to attempt for a better one.

\subsection{Simple Functions}
As the name suggests, a simple function is a function that takes on only finitely many distinct values. 

Example: The Dirichlet function over the real line takes the value 1 if $x$ is rational, 0 otherwise.

A simple function can be written as a linear combination of indicator functions of sets, such as
$$f = c_1\chi_{A_1} +c_2\chi_{A_2}+\dots+c_n\chi_{A_n}$$
$$f = \sum \limits_{i=1}^nc_i\chi_{A_i}$$
Where the indicator function $\chi_A$ denotes whether or not a element is present in the given set.
$$\chi_A(x)=\begin{cases} 
    1 ,\ x \in A \\
    0 ,\ x \notin A
   \end{cases}$$
\subsection{Lebesgue Integral}
The Lebesgue integral for a simple function defined above is:
$$ \int_{\mathbb{R}} fd{\lambda}=c_1\lambda (A_1)+c_2\lambda (A_2)+\dots+c_n\lambda (A_n)$$
$$ \int_{\mathbb{R}} fd{\lambda}=\sum \limits_{i=1}^n c_i\lambda (A_i)$$
Here, $\lambda(A)$ denotes the Lebesgue measure.

If $f$ takes on both positive and negative values, the integral can be evaluated separately for each part.

Finally, the Lebesgue integral of an arbitrary function $f$ is defined by considering approximations of simple functions.
\[ \int_{\mathbb{R}} fd{\lambda}= \sup\limits_{g \leq f \;:\; g \,simple} \int_{\mathbb{R}} gd{\lambda}\]

\subsection{Properties}

\begin{itemize}
    \item     If f, g are functions such that $f = g$ almost everywhere, then $f$ is Lebesgue integrable iff $g$ is Lebesgue integrable, and the integrals of $f$ and $g$ are the same if they exist.
    \item Linearity,
    
    $$\int (c_1f+c_2g )d\lambda= c_1 \int f d\lambda+ c_2 \int g d\lambda$$
    \item Monotonicity, if $f\leq g$,
    
    $$\int f d\lambda \leq \int g d\lambda$$
    \item$$|{\int fd\lambda}| \leq \int |f|d\lambda$$ 
    \item Monotone Convergence Theorem, Suppose $\{ k_n\}_{k \in \mathbb{N}} $is a sequence of non-negative measurable functions such that
    $f_{k}(x) \leq f_{k+1}(x) \forall k \in \mathbb{N}.$
    
    Then, the limit $f$ of $f_k$ is Lebesgue measurable and
    \[ \lim_{k} \int f_k d\lambda = \int f d\lambda\]
    
    \item Dominated Convergence Theorem,  If $|f_n| \leq g$ for an integrable function $g$, and $f_n \to f$, then
    $$ \lim_{n}\int f_n d\lambda =\int f d\lambda$$
\end{itemize}
The Riemann integral does not work well with taking limits of sequences of functions. 

The Lebesgue integral is better able to describe how and when it is possible to take limits under the integral sign (via the monotone convergence theorem and dominated convergence theorem). This is important in the study of Fourier series, Fourier transforms, and other topics. 


\subsection{Example}
The Dirichlet function,

\[ 1_{\mathbb{Q}}(x)=\begin{cases} 
    1 , x \;is\; rational \\
    0 , x \;is\; not\; rational
   \end{cases}
\]
 It is nowhere continuous and not Riemann-integrable.\medskip
 
 The Dirichlet function is Lebesgue-integrable on $\mathbb{R}$ and its integral over $\mathbb{R}$ is zero, as the measure of rational numbers is 0.



\newpage
\section{Conclusion}

We have seen through this report how measures and measure theory is an extremely valuable addition to modern mathematics. It rather generalizes everything that is measurable to a singular concept, the measure. Although it is an abstract topic, it is an integral part of analysis as we have seen through the course of this report.

\bigskip

The Lebesgue measure could be considered one of the most vital contributions to measure theory and even to modern mathematics. We have covered the existence of non-Lebesgue measurable sets, and how these sets give rise to almost impossible seeming paradoxes like the Banach-Tarski paradox. We have seen how Lebesgue measure is used in probability theory and the Lebesgue integral.

\bigskip

We have seen how probability theory often relies on measure theory, and the notion of measures, especially Lebesgue measures. Probability is often used to make educated predictions and estimates, which is vital to investigation. Probability is one of the branches of mathematical study that is often used in other fields, like in the field of statistics, Physics etc. 

\bigskip

The Lebesgue integral opens up many possibilities, many that the Riemann integral cannot. We have seen how the Lebesgue measure and hence the integral is superior when accounting higher dimensions, and the ease in doing so. 


\newpage
\section{References}
\begin{itemize}
    \item Lebesgue Measure and Integration: An Introduction - Frank Burk
    \item Invitation to Ergodic Theory - C.E. Silva
    \item Real Analysis - H.M. Royden \& P.M. Fitzpatrick
    \item Analysis II - Terrence Tao
    \item Measure Theory - Terrence Tao
    \item Probability and Measure - Patrick Billingsley
    \item Principles of Mathematical Analysis - Walter Rudin
    \item Measure Theory and Probability Theory - Krishna B. Athreya and S.N.Lahiri
    \item \href{https://en.wikipedia.org/wiki/Lebesgue_measure}{Lebesgue Measure}
    \item \url{http://math.bme.hu/~nandori/Virtual_lab/stat/prob/Probability.pdf}
    \item \url{http://www.its.caltech.edu/~mshum/stats/lect1.pdf}
    \item \url{http://www.math.tifr.res.in/~publ/ln/tifr12.pdf}
    \item \href{https://faculty.etsu.edu/gardnerr/5210/Beamer-Proofs/Proofs-2-2.pdf}{Some proofs used above}
    \item \href{https://en.wikipedia.org/wiki/Cantor_set}{Cantor Set}
    \item \href{https://en.wikipedia.org/wiki/Vitali_set}{Vitali Set}
    \item \href{https://en.wikipedia.org/wiki/Lebesgue_integration}{Lebesgue Integration}
    
\end{itemize}

\end{document}
